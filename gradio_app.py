# app.py
import gradio as gr
import os
from typing import List, Any
from PIL import Image
import re
import argparse

from model_runtime import ModelRuntime

# ---------------- è¿è¡Œæ—¶å°è£…ï¼ˆçƒ­é‡è½½/ä¸­æ–­/è£å‰ªï¼‰ ----------------
_RUNTIME = ModelRuntime.instance()

def startup_initialize(cfg_path: str = "configs/config.py",
                       save_dir: str = "./outputs",
                       device_str: str = None) -> str:
    """
    å¯åŠ¨æ—¶åˆå§‹åŒ–æ¨¡å‹ï¼Œä»…åŠ è½½ä¸€æ¬¡ã€‚
    """
    return _RUNTIME.initialize(cfg_path=cfg_path, save_dir=save_dir, device_str=device_str)

def runtime_reload(cfg_path: str, save_dir: str, device_str: str) -> str:
    """
    çƒ­é‡è½½æ¨¡å‹ï¼Œé‡æ–°åŠ è½½é…ç½®å’Œæƒé‡ã€‚
    """
    return _RUNTIME.initialize(cfg_path=cfg_path, save_dir=save_dir, device_str=device_str, force_reload=True)

def runtime_clear_history() -> str:
    """
    æ¸…ç©ºå¯¹è¯å†å²ã€‚
    """
    try:
        _RUNTIME.clear_history()
        return "ğŸ§¹ å·²æ¸…ç©ºå¯¹è¯å†å²ã€‚"
    except Exception as e:
        return f"æ¸…ç©ºå†å²å¤±è´¥ï¼š{e}"

def runtime_request_stop() -> str:
    """
    è¯·æ±‚åœæ­¢å½“å‰ç”Ÿæˆã€‚
    """
    _RUNTIME.request_stop()
    return "â¹ï¸ å·²è¯·æ±‚åœæ­¢å½“å‰ç”Ÿæˆã€‚"

def _split_sentences_cn_en(s: str) -> List[str]:
    """
    æŒ‰ä¸­è‹±æ–‡æ ‡ç‚¹åˆ‡åˆ†é•¿æ–‡æœ¬ã€‚
    """
    if not s:
        return []
    parts = re.split(r'([ã€‚ï¼ï¼Ÿï¼›!?;])', s)
    return [p.strip() for p in parts if p.strip()]

def _chunk_text_cn_en(s: str, max_len: int = 80) -> List[str]:
    """
    å°†é•¿æ–‡æœ¬åˆ†å—ï¼Œé¿å…å‰ç«¯æ˜¾ç¤ºè¿‡é•¿çš„æ–‡æœ¬ã€‚
    """
    sentences = _split_sentences_cn_en(s)
    chunks, current_chunk = [], ""
    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= max_len:
            current_chunk += sentence
        else:
            chunks.append(current_chunk)
            current_chunk = sentence
    if current_chunk:
        chunks.append(current_chunk)
    return chunks

def on_submit(text: str, files: List[Any], mode: str, history: List[gr.ChatMessage]):
    """
    æäº¤ç”¨æˆ·è¾“å…¥ï¼Œè§¦å‘ç”Ÿæˆã€‚
    """
    text = (text or "").strip()
    file_paths = [f.name for f in files] if files else []

    # åˆ‡æ¢ mode æ—¶æ›´æ–°é‡‡æ ·å‚æ•°
    _RUNTIME.update_sampling_config(mode)

    # å·¦ä¾§ï¼šç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬å’Œå›¾ç‰‡
    if text:
        history.append(gr.ChatMessage(role="user", content=text))
        yield history, gr.update(value=None), gr.update(value=None), history

    for file_path in file_paths:
        try:
            img = Image.open(file_path).convert("RGB")
            history.append(gr.ChatMessage(role="user", content=[file_path]))
            yield history, gr.update(value=None), gr.update(value=None), history
        except Exception:
            pass

    # ç”Ÿæˆå‡†å¤‡
    _RUNTIME.reset_stop()
    raw_sample = {"text": text, "images": file_paths, "mode": mode}
    _RUNTIME.encode_and_set_prompt(raw_sample)

    # æµå¼ç”Ÿæˆ
    for ev in _RUNTIME.stream_events(max_rounds=64, text_chunk_tokens=64):
        if ev["type"] == "text":
            chunks = _chunk_text_cn_en(ev["text"], max_len=80)
            for chunk in chunks:
                history.append(gr.ChatMessage(role="assistant", content=chunk))
                yield history, gr.update(value=None), gr.update(value=None), history
        elif ev["type"] == "image":
            history.append(gr.ChatMessage(role="assistant", content=ev["paths"]))
            yield history, gr.update(value=None), gr.update(value=None), history

def on_clear():
    """
    æ¸…ç©ºå¯¹è¯å†å²ã€‚
    """
    _RUNTIME.reset_stop()
    _RUNTIME.clear_history()
    return [], None, None, []

# ---------------- UI ----------------

with gr.Blocks(title="Model Text + Multi-Image") as demo:
    gr.Markdown("### è¾“å…¥æ–‡æœ¬ä¸å¤šå›¾ï¼›å³ä¾§æŒ‰**ç”Ÿæˆæ­¥éª¤**ä¾æ¬¡è¾“å‡ºï¼šæ”¯æŒä»»åŠ¡åˆ‡æ¢ã€Stopã€æ¸…ç©ºã€çƒ­é‡è½½ã€‚")

    chatbot = gr.Chatbot(type="messages", height=560, label="Conversation")

    with gr.Row():
        tb = gr.Textbox(label="Text", placeholder="è¾“å…¥æ–‡æœ¬...", lines=2, scale=5)
        mode_dd = gr.Dropdown(
            label="ä»»åŠ¡ç±»å‹",
            choices=["default", "howto", "story", "t2i", "x2i"],
            value="default",
            scale=2,
        )
        files = gr.Files(label="ä¸Šä¼ å›¾ç‰‡", file_types=["image"], file_count="multiple", scale=5)

    with gr.Row():
        send = gr.Button("å‘é€", variant="primary")
        stop = gr.Button("åœæ­¢")
        clear = gr.Button("æ¸…ç©º")

    with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
        cfg_path_tb = gr.Textbox(label="é…ç½®æ–‡ä»¶è·¯å¾„", value="configs/config.py", scale=4)
        save_dir_tb = gr.Textbox(label="è¾“å‡ºç›®å½•", value="./outputs", scale=3)
        device_tb = gr.Textbox(label="è®¾å¤‡", value="cuda:0", scale=2)
        reload_btn = gr.Button("é‡æ–°åŠ è½½æ¨¡å‹", variant="secondary", scale=1)

    state_history = gr.State([])  # å†å²è®°å½•
    ready_msg = gr.Markdown()
    demo.load(lambda: startup_initialize(), outputs=ready_msg)

    tb.submit(on_submit, inputs=[tb, files, mode_dd, state_history], outputs=[chatbot, tb, files, state_history])
    send.click(on_submit, inputs=[tb, files, mode_dd, state_history], outputs=[chatbot, tb, files, state_history])
    stop.click(lambda: runtime_request_stop(), outputs=[])
    clear.click(on_clear, outputs=[chatbot, tb, files, state_history])
    reload_btn.click(lambda cfg, sd, dev: runtime_reload(cfg, sd, dev),
                     inputs=[cfg_path_tb, save_dir_tb, device_tb],
                     outputs=ready_msg)

# ---------------- å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ ----------------

if __name__ == "__main__":
    parser = argparse.ArgumentParser(add_help=True)
    parser.add_argument("--port", type=int, default=None, help="Port for Gradio server")
    parser.add_argument("--host", type=str, default=None, help="Host for Gradio server (e.g. 0.0.0.0)")
    parser.add_argument("--cfg", type=str, default=None, help="Config path for model init (overrides UI)")
    parser.add_argument("--save_dir", type=str, default=None, help="Output directory for generations")
    parser.add_argument("--device", type=str, default=None, help="Device string, e.g. cuda:0 or cpu")
    args, _ = parser.parse_known_args()

    cfg_path = args.cfg or "configs/config.py"
    save_dir = args.save_dir or "./outputs"
    device_str = args.device or None

    print(startup_initialize(cfg_path=cfg_path, save_dir=save_dir, device_str=device_str))

    launch_kwargs = {}
    if args.port is not None:
        launch_kwargs["server_port"] = args.port
    if args.host is not None:
        launch_kwargs["server_name"] = args.host
    demo.launch(**launch_kwargs)