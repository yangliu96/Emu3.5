# app.py
import gradio as gr
import tempfile
import os
import shutil
import uuid
import re
from pathlib import Path
from typing import List, Dict, Any, Union

from PIL import Image, ImageOps
import importlib.util
import torch
import os.path as osp

from model_runtime import ModelRuntime

# ---------------- åŸºç¡€ & å·¥å…· ----------------

def _save_preview(img: Image.Image, max_hw: int = 768) -> str:
    """ä¿å­˜ç¼©æ”¾é¢„è§ˆï¼Œè¿”å›ç»å¯¹è·¯å¾„ï¼ˆä¾› Chatbot ç›´æ¥æ˜¾ç¤ºä¸ºå›¾ç‰‡ï¼‰ã€‚"""
    preview = ImageOps.contain(img, (max_hw, max_hw)).convert("RGB")
    tmp = tempfile.NamedTemporaryFile(suffix=".png", delete=False)
    preview.save(tmp.name, format="PNG")
    tmp.close()
    return os.path.abspath(tmp.name)

def _dup_path(src: str) -> str:
    """å¤åˆ¶ä¸€ä¸ªå…¨æ–°æ–‡ä»¶ï¼Œé¿å…åŒä¸€è·¯å¾„åœ¨å¤šæ¡æ¶ˆæ¯é‡Œå¤ç”¨å¯¼è‡´çš„æ¸²æŸ“é—®é¢˜ã€‚"""
    _, ext = os.path.splitext(src)
    tmp = tempfile.NamedTemporaryFile(suffix=ext or ".png", delete=False)
    tmp.close()
    shutil.copyfile(src, tmp.name)
    return os.path.abspath(tmp.name)

def _to_path_list(files: Union[List[str], List[Dict], None]) -> List[str]:
    """å°† gr.Files è¿”å›å€¼ç»Ÿä¸€æˆè·¯å¾„åˆ—è¡¨ã€‚"""
    paths: List[str] = []
    if not files:
        return paths
    for f in files:
        if isinstance(f, str):
            paths.append(f)
        elif isinstance(f, dict) and "name" in f:
            paths.append(f["name"])
        else:
            name = getattr(f, "name", None)
            if isinstance(name, str):
                paths.append(name)
    return paths

# ---------- æ–‡æœ¬å½’æ¡£ + ä¸­æ–‡å‹å¥½åˆ†å— + å®‰å…¨æ–‡æœ¬æ°”æ³¡ ----------

def _archive_text(text: str, folder: str = None) -> None:
    """
    å–æ¶ˆå†™ç£ç›˜å½’æ¡£ï¼Œé¿å…æŒ‰æ–‡ä»¶ç²’åº¦å¯¼è‡´å‰ç«¯é”™æŠŠæ¯æ¡å½“â€œç‹¬ç«‹æ¶ˆæ¯â€ã€‚
    å¦‚éœ€æ’éšœï¼Œå¯åœ¨æ­¤æ”¹ä¸ºç¯å½¢å†…å­˜æ—¥å¿—æˆ–æŒä¹…åŒ–å¼€å…³ã€‚
    """
    return None

_CJK_SENT_SPLIT = re.compile(r'([ã€‚ï¼ï¼Ÿï¼›!?;])')  # æ•è·åˆ†éš”ç¬¦ä»¥ä¾¿è¿˜åŸ

def _split_sentences_cn_en(s: str) -> List[str]:
    """æŒ‰ä¸­æ–‡/è‹±æ–‡æ ‡ç‚¹ä¸æ¢è¡Œåˆ‡å¥ï¼Œä¿ç•™æ ‡ç‚¹ã€‚"""
    if not s:
        return []
    paras = re.split(r'\n+', s)
    out = []
    for para in paras:
        if not para.strip():
            continue
        parts = _CJK_SENT_SPLIT.split(para)
        for i in range(0, len(parts), 2):
            sent = parts[i]
            punc = parts[i+1] if i+1 < len(parts) else ""
            chunk = (sent + punc).strip()
            if chunk:
                out.append(chunk)
    return out

def _chunk_text_cn_en(s: str, max_len: int = 80) -> List[str]:
    """
    å…ˆæŒ‰å¥åˆ‡ï¼Œå†æŠŠç›¸é‚»å¥æ‹¼åˆ°ä¸è¶…è¿‡ max_lenã€‚
    å¯¹æ— ç©ºæ ¼é•¿ä¸²åšç¡¬åˆ‡ï¼Œä¿è¯æ¯å— <= max_lenã€‚
    """
    sents = _split_sentences_cn_en(s)
    if not sents:
        return []
    chunks, buf = [], ""
    for sent in sents:
        if len(buf) + len(sent) <= max_len:
            buf += (sent if not buf else sent)
        else:
            if buf:
                chunks.append(buf)
            if len(sent) > max_len:
                for i in range(0, len(sent), max_len):
                    piece = sent[i:i+max_len]
                    if piece:
                        chunks.append(piece)
                buf = ""
            else:
                buf = sent
    if buf:
        chunks.append(buf)
    return chunks

def _text_bubbles_safe(role: str, text: str, max_len: int = 80) -> List[gr.ChatMessage]:
    """
    æŠŠä»»æ„é•¿æ–‡æœ¬ -> å¤šæ¡å®‰å…¨çŸ­æ–‡æœ¬æ°”æ³¡ã€‚
    ä»…è¿”å›â€œå†…å®¹æ–‡æœ¬â€ï¼Œä¸è¿”å›å½’æ¡£æ–‡ä»¶è·¯å¾„ã€‚
    æ¯å—å‰ç½®ä¸€ä¸ªé›¶å®½å­—ç¬¦ï¼Œè¿›ä¸€æ­¥é™ä½è¢«è¯¯åˆ¤ä¸ºè·¯å¾„çš„æ¦‚ç‡ã€‚
    """
    msgs = []
    for chunk in _chunk_text_cn_en(text, max_len=max_len):
        msgs.append(gr.ChatMessage(role=role, content="\u2060" + chunk))
    return msgs

# // ---------------- é€æ­¥äº§å‡ºï¼šäº¤ç”± ModelRuntime ç®¡ç† ----------------

# ---------------- è¿è¡Œæ—¶å°è£…ï¼ˆçƒ­é‡è½½/ä¸­æ–­/è£å‰ªï¼‰ ----------------
_RUNTIME = ModelRuntime.instance()

def startup_initialize(cfg_path: str = "config/app_config.py",
                       save_dir: str = "./outputs",
                       device_str: str = None) -> str:
    return _RUNTIME.initialize(cfg_path=cfg_path, save_dir=save_dir, device_str=device_str)

def runtime_reload(cfg_path: str, save_dir: str, device_str: str) -> str:
    return _RUNTIME.initialize(cfg_path=cfg_path or "config/app_config.py",
                               save_dir=save_dir or "./outputs",
                               device_str=(device_str or None),
                               force_reload=True)

def runtime_clear_history() -> str:
    try:
        _RUNTIME.clear_history()
        return "ğŸ§¹ å·²æ¸…ç©ºå¯¹è¯å†å²ï¼ˆä»…æ¨¡å‹æ€ï¼‰ã€‚"
    except Exception as e:
        return f"æ¸…ç©ºå†å²å¤±è´¥ï¼š{e}"

def runtime_request_stop() -> str:
    _RUNTIME.request_stop()
    return "â¹ï¸ å·²è¯·æ±‚åœæ­¢å½“å‰ç”Ÿæˆã€‚"

# ---------------- æ‰“åŒ… sample ----------------

VIS_TOKEN = "<|VIS_PLH|>"
SUP_START = "<|extra_100|>"
SUP_END   = "<|extra_101|>"

def pack_sample(sample: Dict[str, Any]) -> Dict[str, Any]:
    """
    å°† {text, images[]} æ‰“åŒ…ä¸º:
    {
        "text_prompt": "You are a helpful assistant. USER: {text + VIS*n}ASSISTANT: <|extra_100|>",
        "visual_placeholder": "<|VIS_PLH|>",
        "supervised_start": "<|extra_100|>",
        "supervised_end": "<|extra_101|>",
        "image_list": [...]
    }
    - VIS_TOKEN æ•°é‡ == å›¾ç‰‡æ•°é‡
    - è‹¥ text å†…å·²æœ‰ VIS_TOKENï¼Œå…ˆç§»é™¤å†æŒ‰æ•°é‡é‡æ’
    """
    text = (sample.get("text") or "").strip()
    images_in = sample.get("images") or []
    image_list: List[str] = [str(p) for p in images_in if p]
    n_vis = len(image_list)

    vis_re = re.compile(rf"\s*{re.escape(VIS_TOKEN)}\s*")
    text_wo_vis = vis_re.sub(" ", text).strip()
    text_wo_vis = re.sub(r"\s+", " ", text_wo_vis)

    if n_vis > 0:
        vis_suffix = " " + " ".join([VIS_TOKEN] * n_vis)
        user_text = (text_wo_vis + vis_suffix).strip()
    else:
        user_text = text_wo_vis

    mode = (sample.get("mode") or "").strip()
    if not mode or mode == "default":
        system_prefix = "You are a helpful assistant."
    if mode == "howto_new":
        system_prefix = "You are a helpful assistant for howto task. Please generate a response with interleaved text and images."
    else:
        system_prefix = f"You are a helpful assistant for {mode} task."
    print("system_prefix: {}".format(system_prefix))
    text_prompt = f"{system_prefix} USER: {user_text} ASSISTANT: {SUP_START}"
    return {
        "text_prompt": text_prompt,
        "visual_placeholder": VIS_TOKEN,
        "supervised_start": SUP_START,
        "supervised_end": SUP_END,
        "image_list": image_list,
    }

# ---------------- å›è°ƒï¼ˆç›´æ¥ç”¨å·²åˆå§‹åŒ–çš„å…¨å±€æ¨¡å‹ï¼‰ ----------------

def on_submit(text: str, files: List[Any], mode: str, history: List[gr.ChatMessage]):
    text = (text or "").strip()
    file_paths = _to_path_list(files)

    # å·¦ä¾§ï¼šç”¨æˆ·æ–‡æœ¬ï¼ˆå•æ¡æ°”æ³¡ï¼Œä¸å†åˆ†å—/å½’æ¡£ï¼‰
    if text:
        history = history + [gr.ChatMessage(role="user", content="\u2060" + text)]
        yield history, gr.update(value=None), gr.update(value=None), history

    # å·¦ä¾§ï¼šç”¨æˆ·å›¾ç‰‡ï¼ˆé€å¼ å•ç‹¬æ°”æ³¡ï¼‰
    for p in file_paths:
        try:
            im = Image.open(p).convert("RGB")
            up = _save_preview(im, max_hw=768)
            history = history + [gr.ChatMessage(role="user", content=[up])]
            yield history, gr.update(value=None), gr.update(value=None), history
        except Exception:
            pass

    # ç”Ÿæˆå‡†å¤‡ï¼šé‡ç½® stop æ ‡å¿—ï¼Œæ‰“åŒ…æ ·æœ¬å¹¶è®¾ç½®åˆ°è¿è¡Œæ—¶
    _RUNTIME.reset_stop()
    raw_sample = {"text": text, "images": [os.path.abspath(p) for p in file_paths], "mode": (mode or "").strip()}
    sample = pack_sample(raw_sample)
    _RUNTIME.encode_and_set_prompt(sample)

    # å³ä¾§ï¼šçœŸæ­£æµå¼â€”â€”äº‹ä»¶é©±åŠ¨ï¼ˆtext å°å—å³æ—¶ã€image å®Œæ•´åå³å¯ä¸Šå±ï¼‰
    acc_text = ""
    has_open_text = False
    for ev in _RUNTIME.stream_events(max_rounds=64, text_chunk_tokens=64):
        if ev.get("type") == "text":
            chunk = ev.get("text", "")
            if chunk:
                acc_text += chunk
                if not has_open_text or not history or history[-1].role != "assistant" or not isinstance(history[-1].content, str):
                    # æ–°å»ºä¸€ä¸ªåŠ©æ‰‹æ–‡æœ¬æ°”æ³¡
                    history = history + [gr.ChatMessage(role="assistant", content="\u2060" + acc_text)]
                    has_open_text = True
                else:
                    # æ›´æ–°æœ€åä¸€ä¸ªåŠ©æ‰‹æ–‡æœ¬æ°”æ³¡
                    history = history[:-1] + [gr.ChatMessage(role="assistant", content="\u2060" + acc_text)]
                yield history, gr.update(value=None), gr.update(value=None), history
        elif ev.get("type") == "image":
            # å…³é—­å½“å‰æ–‡æœ¬æ°”æ³¡ï¼Œåç»­æ–‡æœ¬æ–°å»º
            has_open_text = False
            acc_text = ""
            for ip in ev.get("paths", []):
                echoed = _dup_path(ip)
                history = history + [gr.ChatMessage(role="assistant", content=[echoed])]
                yield history, gr.update(value=None), gr.update(value=None), history

def on_clear():
    _RUNTIME.reset_stop()
    try:
        _RUNTIME.clear_history()
    except Exception:
        pass
    return [], None, None, []

# ---------------- UI ----------------

with gr.Blocks(title="Model Text + Multi-Image (separate bubbles)") as demo:
    gr.Markdown("### è¾“å…¥æ–‡æœ¬ä¸å¤šå›¾ï¼›å³ä¾§æŒ‰**ç”Ÿæˆæ­¥éª¤**ä¾æ¬¡è¾“å‡ºï¼šæ–‡æœ¬è‡ªåŠ¨ä¸­æ–‡å‹å¥½åˆ†å—ï¼›æ”¯æŒ Stop/æ¸…ç©º/çƒ­é‡è½½ï¼›æ˜¾å­˜å‹å¥½ã€‚")

    chatbot = gr.Chatbot(type="messages", height=560, label="Conversation")

    with gr.Row():
        tb = gr.Textbox(
            label="Text",
            placeholder="Type somethingâ€¦ (press Enter to send)",
            lines=2,
            autofocus=True,
            scale=5,
        )
        mode_dd = gr.Dropdown(
            label="System Prompt",
            choices=[
                "default",
                "lang",
                "vl",
                "t2i",
                "x2i",
                "howto",
                "story",
                "vla",
                "explore",
                "howto_new",
            ],
            value="default",
            scale=2,
        )
        files = gr.Files(
            label="Images (drop multiple here)",
            file_types=["image"],
            file_count="multiple",
            scale=5,
        )

    with gr.Row():
        send = gr.Button("Send", variant="primary")
        stop = gr.Button("Stop")
        clear = gr.Button("Clear")

    with gr.Accordion("é«˜çº§è®¾ç½®ï¼ˆæ¨¡å‹çƒ­é‡è½½ / è®¾å¤‡ / è¾“å‡ºç›®å½•ï¼‰", open=False):
        with gr.Row():
            cfg_path_tb = gr.Textbox(label="Config Path", value="config/app_config.py", scale=4)
            save_dir_tb = gr.Textbox(label="Save Dir", value="./outputs", scale=3)
            device_tb = gr.Textbox(label="Device (e.g. cuda:0 / cpu)", value="", scale=2)
            reload_btn = gr.Button("Reload Model", variant="secondary", scale=1)

    state_history = gr.State([])  # åªå­˜å†å²ï¼Œå¯ deep copy
    ready_msg = gr.Markdown()
    demo.load(lambda: startup_initialize(), outputs=ready_msg)

    tb.submit(on_submit, inputs=[tb, files, mode_dd, state_history],
              outputs=[chatbot, tb, files, state_history])
    send.click(on_submit, inputs=[tb, files, mode_dd, state_history],
               outputs=[chatbot, tb, files, state_history])
    stop.click(lambda: runtime_request_stop(), outputs=[])
    clear.click(on_clear, outputs=[chatbot, tb, files, state_history])

    reload_btn.click(lambda cfg, sd, dev: runtime_reload(cfg, sd, dev),
                     inputs=[cfg_path_tb, save_dir_tb, device_tb],
                     outputs=ready_msg)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(add_help=True)
    parser.add_argument("--port", type=int, default=None, help="Port for Gradio server")
    parser.add_argument("--host", type=str, default=None, help="Host for Gradio server (e.g. 0.0.0.0)")
    parser.add_argument("--cfg", type=str, default=None, help="Config path for model init (overrides UI)")
    parser.add_argument("--save_dir", type=str, default=None, help="Output directory for generations")
    parser.add_argument("--device", type=str, default=None, help="Device string, e.g. cuda:0 or cpu")
    args, _ = parser.parse_known_args()

    cfg_path = args.cfg or "config/app_config.py"
    save_dir = args.save_dir or "./outputs"
    device_str = args.device or None

    print(startup_initialize(cfg_path=cfg_path, save_dir=save_dir, device_str=device_str))

    launch_kwargs = {}
    if args.port is not None:
        launch_kwargs["server_port"] = args.port
    if args.host is not None:
        launch_kwargs["server_name"] = args.host
    demo.launch(**launch_kwargs)